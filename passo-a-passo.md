# Passo-a-Passo: Como Executar e Monitorar o Pipeline DataOps

## üöÄ **CONFIGURA√á√ÉO INICIAL**

### Passo 1: Preparar o Ambiente
```bash
# 1. Configura√ß√£o completa (primeira vez)
make dev-setup

# OU se j√° tem o ambiente:
make up
```

**O que acontece:**
- ‚úÖ Cria diret√≥rios necess√°rios
- ‚úÖ Copia arquivo .env
- ‚úÖ Constr√≥i imagens Docker
- ‚úÖ Inicia todos os servi√ßos
- ‚úÖ Aguarda 30 segundos para inicializa√ß√£o

### Passo 2: Verificar se Tudo Est√° Funcionando
```bash
make status
```

**Voc√™ deve ver algo assim:**
```
       Name                     Command               State           Ports         
-----------------------------------------------------------------------------------
adminer              entrypoint.sh docker-php-e...   Up      0.0.0.0:8081->8080/tcp
airflow-scheduler    /usr/bin/dumb-init -- /ent...   Up      8080/tcp              
airflow-webserver    /usr/bin/dumb-init -- /ent...   Up      0.0.0.0:8080->8080/tcp
grafana              /run.sh                          Up      0.0.0.0:3000->3000/tcp
jupyter              tini -g -- start-notebook.sh    Up      0.0.0.0:8888->8888/tcp
minio                /usr/bin/docker-entrypoint ...   Up      0.0.0.0:9001->9001/tcp
postgres-airflow     docker-entrypoint.sh postgres   Up      0.0.0.0:5433->5432/tcp
postgres-data        docker-entrypoint.sh postgres   Up      0.0.0.0:5432->5432/tcp
prometheus           /bin/prometheus --config.f...   Up      0.0.0.0:9090->9090/tcp
redis                docker-entrypoint.sh redis ...   Up      0.0.0.0:6379->6379/tcp
```

---

## üìä **EXECUTANDO O PIPELINE**

### Passo 3: Executar o Pipeline ETL
```bash
make test-pipeline
```

**Sa√≠da esperada:**
```
Testando pipeline ETL...
Triggering DAG with dag_id: etl_pipeline
Pipeline triggerado. Verifique o status no Airflow UI.
```

### Passo 4: Monitorar a Execu√ß√£o (3 Op√ß√µes)

#### **OP√á√ÉO A: Airflow UI (Visual - Recomendado)**
1. **Abra o navegador:** http://localhost:8080
2. **Login:** `admin` / `admin`
3. **Clique em:** "DAGs" ‚Üí "etl_pipeline"
4. **Veja a execu√ß√£o:** Clique na execu√ß√£o mais recente

**O que voc√™ ver√°:**
- üîµ **Azul**: Task em execu√ß√£o
- üü¢ **Verde**: Task conclu√≠da com sucesso
- üî¥ **Vermelho**: Task falhou
- ‚ö™ **Branco**: Task aguardando

#### **OP√á√ÉO B: Logs em Tempo Real (Terminal)**
```bash
# Terminal 1: Logs do Airflow
make logs-airflow

# Terminal 2: Logs de todos os servi√ßos
make logs
```

#### **OP√á√ÉO C: Status dos Containers**
```bash
# Verificar se containers est√£o rodando
make status

# Verificar sa√∫de dos servi√ßos
make check-health
```

---

## üîç **VERIFICANDO OS RESULTADOS**

### Passo 5: Verificar Dados no Banco
1. **Abra:** http://localhost:8081 (Adminer)
2. **Conecte:**
   - **Server:** `postgres-data`
   - **Username:** `dataops`
   - **Password:** `dataops123`
   - **Database:** `datawarehouse`
3. **Execute queries:**
```sql
-- Ver tabelas criadas
SELECT table_name FROM information_schema.tables 
WHERE table_schema = 'public';

-- Ver dados de usu√°rios
SELECT * FROM users LIMIT 10;

-- Ver dados de posts
SELECT * FROM posts LIMIT 10;

-- Ver m√©tricas processadas
SELECT * FROM processed_metrics;
```

### Passo 6: An√°lise no Jupyter
1. **Abra:** http://localhost:8888
2. **Token:** `dataops123`
3. **Abra o notebook:** `data_analysis.ipynb`
4. **Execute as c√©lulas** para ver an√°lises

### Passo 7: Dashboards no Grafana
1. **Abra:** http://localhost:3000
2. **Login:** `admin` / `admin`
3. **V√° para:** Dashboards ‚Üí Browse
4. **Veja m√©tricas:** Sistema, Airflow, Pipeline

---

## üîß **COMANDOS √öTEIS DURANTE EXECU√á√ÉO**

### Monitoramento Cont√≠nuo
```bash
# Ver logs espec√≠ficos do Airflow (recomendado)
make logs-airflow

# Ver logs de todos os servi√ßos
make logs

# Ver apenas logs do PostgreSQL
make logs-postgres

# Status dos containers
make status
```

### Controle do Pipeline
```bash
# Listar todas as DAGs
make list-dags

# Triggerar novamente o pipeline
make trigger-dag

# Reiniciar todos os servi√ßos
make restart
```

---

## üìà **INTERFACES DE MONITORAMENTO**

### Todas as URLs de Acesso:
| Servi√ßo | URL | Credenciais |
|---------|-----|-------------|
| **Airflow** | http://localhost:8080 | admin/admin |
| **Jupyter** | http://localhost:8888 | token: dataops123 |
| **Grafana** | http://localhost:3000 | admin/admin |
| **Adminer** | http://localhost:8081 | dataops/dataops123 |
| **MinIO** | http://localhost:9001 | minioadmin/minioadmin123 |
| **Prometheus** | http://localhost:9090 | - |

### Comando R√°pido para Abrir Tudo:
```bash
make monitor    # Abre Grafana, Prometheus e Airflow
make jupyter    # Abre Jupyter
```

---

## üîÑ **FLUXO COMPLETO DO PIPELINE**

### O que acontece quando voc√™ executa `make test-pipeline`:

1. **Extract (Extra√ß√£o)**
   - üì° Busca dados da API JSONPlaceholder
   - üíæ Salva dados brutos em `/data/raw/`
   - üóÑÔ∏è Extrai dados do banco fonte

2. **Transform (Transforma√ß√£o)**
   - üßπ Limpa e valida dados
   - üîÑ Aplica transforma√ß√µes de neg√≥cio
   - üìä Calcula m√©tricas agregadas
   - üíæ Salva dados processados em `/data/processed/`

3. **Load (Carregamento)**
   - üóÑÔ∏è Carrega dados no Data Warehouse
   - üìã Atualiza tabelas de dimens√£o e fato
   - ‚úÖ Valida integridade dos dados

### Arquivos Gerados:
```
data/
‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îú‚îÄ‚îÄ users.csv
‚îÇ   ‚îú‚îÄ‚îÄ posts.csv
‚îÇ   ‚îî‚îÄ‚îÄ weather.csv
‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îú‚îÄ‚îÄ users_cleaned.csv
‚îÇ   ‚îú‚îÄ‚îÄ posts_processed.csv
‚îÇ   ‚îî‚îÄ‚îÄ metrics.csv
‚îî‚îÄ‚îÄ warehouse/
    ‚îî‚îÄ‚îÄ final_dataset.csv
```

---

## üö® **TROUBLESHOOTING**

### Problema: Servi√ßos n√£o iniciam
```bash
# Verificar portas em uso
netstat -tlnp | grep -E ':(8080|8888|3000|5432|6379)'

# Reiniciar tudo
make down
make up
```

### Problema: Pipeline falha
```bash
# Ver logs detalhados
make logs-airflow

# Verificar no Airflow UI
# http://localhost:8080 ‚Üí DAGs ‚Üí etl_pipeline ‚Üí Clique na execu√ß√£o falhada
```

### Problema: Dados n√£o aparecem
```bash
# Verificar conex√µes no Airflow UI
# Admin ‚Üí Connections ‚Üí Verificar postgres_default

# Testar conex√£o com banco
docker-compose exec postgres-data psql -U dataops -d datawarehouse -c "SELECT NOW();"
```

### Reset Completo:
```bash
make clean      # Remove tudo
make dev-setup  # Reconfigura ambiente
```

---

## üìä **VALIDANDO O SUCESSO**

### ‚úÖ Checklist de Valida√ß√£o:

#### 1. **Airflow UI**
- [ ] DAG `etl_pipeline` aparece na lista
- [ ] Execu√ß√£o mostra todas as tasks verdes
- [ ] Logs n√£o mostram erros cr√≠ticos

#### 2. **Banco de Dados**
- [ ] Tabelas `users`, `posts`, `weather` existem
- [ ] Dados foram inseridos (contagem > 0)
- [ ] Tabela `processed_metrics` tem m√©tricas

#### 3. **Arquivos**
- [ ] Diret√≥rio `data/raw/` tem arquivos CSV
- [ ] Diret√≥rio `data/processed/` tem dados limpos
- [ ] Logs em `airflow/logs/` s√£o gerados

#### 4. **Monitoramento**
- [ ] Grafana mostra m√©tricas do sistema
- [ ] Prometheus coleta m√©tricas
- [ ] Jupyter abre notebooks corretamente

### Comandos de Valida√ß√£o:
```bash
# 1. Verificar execu√ß√£o da DAG
make list-dags

# 2. Contar registros no banco
docker-compose exec postgres-data psql -U dataops -d datawarehouse -c "
SELECT 'users' as table_name, COUNT(*) as count FROM users
UNION ALL
SELECT 'posts' as table_name, COUNT(*) as count FROM posts;"

# 3. Verificar arquivos gerados
ls -la data/raw/
ls -la data/processed/

# 4. Status final
make status
```

---

## üéØ **PR√ìXIMOS PASSOS**

### Depois que tudo funcionar:
1. **Explore o Jupyter:** Fa√ßa an√°lises dos dados
2. **Configure Alertas:** No Grafana, crie alertas personalizados
3. **Teste Falhas:** Simule erros para ver como o sistema reage
4. **Customize:** Modifique o pipeline para seus dados

### Para Produ√ß√£o:
```bash
make prod-setup  # Configura√ß√£o otimizada para produ√ß√£o
```

---

## üìû **SUPORTE**

### Em caso de problemas:
1. **Verificar logs:** `make logs-airflow`
2. **Status dos servi√ßos:** `make status`
3. **Reset completo:** `make clean && make dev-setup`
4. **Documenta√ß√£o:** Consulte `CLAUDE.md` e `class.md`

### Comandos de Diagn√≥stico:
```bash
docker ps -a              # Todos os containers
docker system df          # Uso de espa√ßo
docker-compose logs -f    # Logs detalhados
```

**üéâ Sucesso!** Agora voc√™ tem um pipeline DataOps completo funcionando!